{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a8b26c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiyon\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "import os\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55d7e8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(filepath:str, label=None) -> list:\n",
    "    '''\n",
    "    Reads dataset in .fa format\n",
    "    returns a list of strings\n",
    "    '''\n",
    "    # Open the file in read-only mode ('r')\n",
    "    output = []\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            if not line.startswith(\">\"):\n",
    "                # This line contains sequence data\n",
    "                output.append(line.strip())\n",
    "        file.close()\n",
    "\n",
    "    return output\n",
    "\n",
    "def conv_amino_to_vector(sequence):\n",
    "    conversion_dict = {\n",
    "        'X':0,\n",
    "        'A':1,\n",
    "        'C':2,\n",
    "        'D':3,\n",
    "        'E':4,\n",
    "        'F':5,\n",
    "        'G':6,\n",
    "        'H':7,\n",
    "        'I':8,\n",
    "        'K':9,\n",
    "        'L':10,\n",
    "        'M':11,\n",
    "        'N':12,\n",
    "        'P':13,\n",
    "        'Q':14,\n",
    "        'R':15,\n",
    "        'S':16,\n",
    "        'T':17,\n",
    "        'V':18,\n",
    "        'W':19,\n",
    "        'Y':20\n",
    "    }\n",
    "\n",
    "    return [conversion_dict[c] for c in sequence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ed1081e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "712"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = read('data/AMP.tr.fa')\n",
    "raw_data_neg = read('data/DECOY.tr.fa')\n",
    "len(raw_data_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8426921e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0  0  0 ... 16 18 17]\n",
      " [ 0  0  0 ... 12 19  2]\n",
      " [ 0  0  0 ...  6 16  6]\n",
      " ...\n",
      " [ 0  0  0 ...  3 10 10]\n",
      " [ 0  0  0 ...  9 10 13]\n",
      " [ 0  0  0 ...  4 14  8]], shape=(12, 200), dtype=int32) tf.Tensor([0 1 0 0 1 0 0 0 1 0 0 0], shape=(12,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 12\n",
    "class Dataset:\n",
    "    def __init__(self, batch_size=32):\n",
    "        self.batch_size = batch_size # specifies how big to make batch\n",
    "        self.data_train = []\n",
    "        for i in raw_data:\n",
    "            padded = i.rjust(200, 'X')\n",
    "            self.data_train.append((conv_amino_to_vector(padded), 1))\n",
    "        for i in raw_data_neg:\n",
    "            padded = i.rjust(200, 'X')\n",
    "            self.data_train.append((conv_amino_to_vector(padded), 0))\n",
    "        self.indices = np.arange(len(self.data_train))\n",
    "        np.random.shuffle(self.indices)\n",
    "    def __len__(self):\n",
    "        return int(len(self.data_train)/self.batch_size)\n",
    "    def __getitem__(self, index):\n",
    "        start = index*self.batch_size\n",
    "        Xs = []\n",
    "        Ys = []\n",
    "        for i in self.indices[start:start+self.batch_size]:\n",
    "            x,y = self.data_train[i]\n",
    "            Xs.append(x)\n",
    "            Ys.append(y)\n",
    "        return np.array(Xs, dtype = np.int32), np.array(Ys, dtype = np.int32)\n",
    "    def __call__(self):\n",
    "        for i in range(self.__len__()):\n",
    "            yield self.__getitem__(i)\n",
    "            \n",
    "            self.on_epoch_end()\n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.indices)\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    Dataset(batch_size = batch_size),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(batch_size, 200), dtype=tf.int32),\n",
    "        tf.TensorSpec(shape=(batch_size), dtype=tf.int32)\n",
    "    )\n",
    ")\n",
    "     \n",
    "\n",
    "for x,y in dataset:\n",
    "    print(x, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4f20ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Embedding(200, 128, input_shape = (200,), name=\"embed\"),\n",
    "        layers.Conv1D(filters = 64, kernel_size = 16, activation=\"relu\", name=\"conv\"),\n",
    "        layers.MaxPooling1D(pool_size = 5, name = 'pooling'),\n",
    "        layers.LSTM(units = 100, unroll = True, stateful = False, dropout = 0.1, name = 'lstm'),\n",
    "        layers.Dense(1, activation = 'sigmoid')\n",
    "    ]\n",
    ")\n",
    "\n",
    "adam = keras.optimizers.Adam()\n",
    "model.compile(loss='binary_crossentropy', metrics = 'accuracy', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbf54be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "118/118 [==============================] - 5s 19ms/step - loss: 0.4547 - accuracy: 0.7782\n",
      "Epoch 2/10\n",
      "118/118 [==============================] - 2s 17ms/step - loss: 0.2869 - accuracy: 0.8870\n",
      "Epoch 3/10\n",
      "118/118 [==============================] - 2s 17ms/step - loss: 0.2366 - accuracy: 0.9032\n",
      "Epoch 4/10\n",
      "118/118 [==============================] - 2s 17ms/step - loss: 0.1751 - accuracy: 0.9315\n",
      "Epoch 5/10\n",
      "118/118 [==============================] - 2s 18ms/step - loss: 0.1301 - accuracy: 0.9506\n",
      "Epoch 6/10\n",
      "118/118 [==============================] - 2s 17ms/step - loss: 0.0991 - accuracy: 0.9668\n",
      "Epoch 7/10\n",
      "118/118 [==============================] - 2s 17ms/step - loss: 0.0733 - accuracy: 0.9760\n",
      "Epoch 8/10\n",
      "118/118 [==============================] - 2s 17ms/step - loss: 0.0638 - accuracy: 0.9781\n",
      "Epoch 9/10\n",
      "118/118 [==============================] - 2s 16ms/step - loss: 0.0481 - accuracy: 0.9866\n",
      "Epoch 10/10\n",
      "118/118 [==============================] - 2s 17ms/step - loss: 0.0531 - accuracy: 0.9788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x14c377bb0d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataset, batch_size = batch_size, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69e324c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 512ms/step\n",
      "[[9.9657983e-01]\n",
      " [9.7498298e-01]\n",
      " [9.9999976e-01]\n",
      " [9.9999875e-01]\n",
      " [9.9999267e-01]\n",
      " [9.9981344e-01]\n",
      " [4.3373186e-02]\n",
      " [2.4834611e-03]\n",
      " [9.9999976e-01]\n",
      " [4.0834875e-05]\n",
      " [9.9179977e-01]\n",
      " [4.8334587e-05]] tf.Tensor([1 1 1 1 1 1 0 0 1 0 1 0], shape=(12,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for x,y in dataset:\n",
    "    x\n",
    "print(model.predict(x),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0b8503",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
